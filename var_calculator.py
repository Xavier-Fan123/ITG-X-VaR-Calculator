"""
ITG-Xç³»ç»Ÿ - é›†å›¢é£é™©ä»·å€¼è®¡ç®—å™¨
ITG-X System - Group Value at Risk (VaR) Calculator

A production-grade, data-driven VaR calculator using:
- Parametric VaR (Variance-Covariance Method)
- EWMA (Exponentially Weighted Moving Average) for volatility modeling
- Full correlation matrix for diversification/netting effects
- Basis risk capture between futures (Settlement) and spot prices

Author: Xavier Fan
"""

from __future__ import annotations

import warnings
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
from scipy.stats import norm

warnings.filterwarnings("ignore")


# =============================================================================
# Data Classes
# =============================================================================

@dataclass
class AssetMetadata:
    """Metadata for a single asset (product + price type combination)."""
    asset_id: str           # e.g., "CUFI_Settlement"
    product_id: str         # e.g., "CUFI"
    product_name: str       # e.g., "æ²ªé“œåŠ æƒ-ä¸œæ–¹è´¢å¯Œ"
    price_type: str         # "Settlement" or "Spot"
    unit: str               # e.g., "TON", "KG", "G", "BUK"
    currency: str           # "CNY" or "USD"

    @property
    def display_name(self) -> str:
        """Human-readable display name for UI."""
        price_label = "æœŸè´§" if self.price_type == "Settlement" else "ç°è´§"
        return f"{self.product_name} ({price_label})"

    @property
    def short_name(self) -> str:
        """Short name for tables."""
        return f"{self.product_id}_{self.price_type}"


# =============================================================================
# FX Service
# =============================================================================

class FXService:
    """
    Service for fetching live exchange rates.
    Uses yfinance with fallback to default values.
    """

    DEFAULT_USDCNY = 7

    @staticmethod
    def get_usdcny_rate() -> Tuple[float, bool]:
        """
        Fetch live USD/CNY exchange rate.

        Returns:
            Tuple of (rate, is_live) where is_live indicates if rate was fetched successfully.
        """
        try:
            import yfinance as yf

            ticker = yf.Ticker("CNY=X")
            # Get the most recent price
            hist = ticker.history(period="1d")

            if not hist.empty and "Close" in hist.columns:
                rate = float(hist["Close"].iloc[-1])
                if 5.0 < rate < 10.0:  # Sanity check for reasonable FX rate
                    return rate, True

            # Try alternative method - fast_info
            if hasattr(ticker, 'fast_info'):
                rate = ticker.fast_info.get('lastPrice', None)
                if rate and 5.0 < rate < 10.0:
                    return rate, True

        except Exception as e:
            st.warning(f"è·å–å®æ—¶æ±‡ç‡å¤±è´¥: {str(e)[:50]}... ä½¿ç”¨é»˜è®¤å€¼")

        return FXService.DEFAULT_USDCNY, False


# =============================================================================
# Data Ingestion Class
# =============================================================================

class DataIngestion:
    """
    Responsible for loading, transforming, and cleaning price data.

    Handles:
    - Reading Excel/CSV files
    - Pivoting from long to wide format
    - Forward-filling missing data
    - Extracting asset metadata
    """

    # Column name mapping (Chinese -> English)
    COLUMN_MAP = {
        "åˆçº¦ç»†åˆ™ID": "ProductID",
        "åˆçº¦ç»†åˆ™æè¿°": "ProductName",
        "æŠ¥ä»·æ—¥æœŸ": "Date",
        "ç»“ç®—ä»·": "Settlement",
        "ç°è´§ä»·æ ¼": "Spot",
        "æŠ¥ä»·å•ä½": "Unit",
        "æŠ¥ä»·è´§å¸": "Currency"
    }

    def __init__(self, file_path: str):
        """
        Initialize the DataIngestion class.

        Args:
            file_path: Path to the Excel/CSV file containing price data.
        """
        self.file_path = file_path
        self._raw_data: Optional[pd.DataFrame] = None
        self._price_matrix: Optional[pd.DataFrame] = None
        self._asset_metadata: Optional[List[AssetMetadata]] = None

    def load_data(self) -> pd.DataFrame:
        """
        Load and preprocess the raw data file.

        Returns:
            DataFrame with standardized column names.

        Raises:
            ValueError: If file format is not supported or required columns are missing.
        """
        if self._raw_data is not None:
            return self._raw_data

        try:
            if self.file_path.lower().endswith(('.xlsx', '.xls')):
                df = pd.read_excel(self.file_path)
            elif self.file_path.lower().endswith('.csv'):
                df = pd.read_csv(self.file_path)
            else:
                raise ValueError(f"Unsupported file format: {self.file_path}")
        except Exception as e:
            raise ValueError(f"Error reading file: {str(e)}")

        # Rename columns to English
        df.columns = [self.COLUMN_MAP.get(col, col) for col in df.columns]

        # Validate required columns
        required_cols = ["ProductID", "Date", "Settlement", "Spot", "Unit", "Currency"]
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")

        # Ensure Date is datetime
        df["Date"] = pd.to_datetime(df["Date"])

        # Sort by date
        df = df.sort_values("Date")

        self._raw_data = df
        return df

    def get_asset_metadata(self) -> List[AssetMetadata]:
        """
        Extract metadata for all available assets.

        æ–°é€»è¾‘ï¼ˆæ–¹æ¡ˆ2ï¼‰ï¼š
        - ä¸å†å‡è®¾æ¯ä¸ª ProductID éƒ½æœ‰ Settlement å’Œ Spot
        - æ ¹æ®å®é™…æ•°æ®åˆ¤æ–­ï¼šæœŸè´§ID (å¦‚ "SG180 Apr26") åªæœ‰ Settlement
        - ç°è´§ID (å¦‚ "SG180") åªæœ‰ Spot

        Returns:
            List of AssetMetadata objects for each product/price-type combination.
        """
        if self._asset_metadata is not None:
            return self._asset_metadata

        df = self.load_data()

        # Get unique products with their metadata
        products = df.groupby("ProductID").agg({
            "ProductName": "first",
            "Unit": "first",
            "Currency": "first"
        }).reset_index()

        metadata_list = []

        for _, row in products.iterrows():
            product_id = row['ProductID']

            # è·å–è¯¥ ProductID çš„æ‰€æœ‰æ•°æ®
            product_data = df[df["ProductID"] == product_id]

            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ Settlement æ•°æ®ï¼ˆéå…¨ NaNï¼‰
            has_settlement = product_data["Settlement"].notna().any()

            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ Spot æ•°æ®ï¼ˆéå…¨ NaNï¼‰
            has_spot = product_data["Spot"].notna().any()

            if has_settlement:
                # Create Settlement asset
                metadata_list.append(AssetMetadata(
                    asset_id=f"{product_id}_Settlement",
                    product_id=product_id,
                    product_name=row["ProductName"],
                    price_type="Settlement",
                    unit=row["Unit"],
                    currency=row["Currency"]
                ))

            if has_spot:
                # Create Spot asset
                metadata_list.append(AssetMetadata(
                    asset_id=f"{product_id}_Spot",
                    product_id=product_id,
                    product_name=row["ProductName"],
                    price_type="Spot",
                    unit=row["Unit"],
                    currency=row["Currency"]
                ))

        # Sort by product ID for consistent ordering
        metadata_list.sort(key=lambda x: (x.product_id, x.price_type))

        self._asset_metadata = metadata_list
        return metadata_list

    def get_price_matrix(self, lookback_days: int = 250) -> pd.DataFrame:
        """
        Generate a wide-format price matrix with forward-filled missing values.

        æ–°é€»è¾‘ï¼ˆæ–¹æ¡ˆ2ï¼‰ï¼š
        - æœŸè´§ID (å¦‚ "SG180 Apr26") åªæœ‰ Settlement åˆ—
        - ç°è´§ID (å¦‚ "SG180") åªæœ‰ Spot åˆ—
        - åˆ é™¤å…¨æ˜¯ NaN çš„åˆ—

        Args:
            lookback_days: Number of most recent trading days to include.

        Returns:
            DataFrame with dates as index and asset prices as columns.
            Column names follow pattern: "{ProductID}_{Settlement|Spot}"
        """
        if self._price_matrix is not None:
            # Check if we have enough rows for the lookback
            if len(self._price_matrix) >= lookback_days:
                return self._price_matrix.tail(lookback_days)
            return self._price_matrix

        df = self.load_data()

        # Pivot Settlement prices
        settlement_pivot = df.pivot_table(
            index="Date",
            columns="ProductID",
            values="Settlement",
            aggfunc="first"
        )
        settlement_pivot.columns = [f"{col}_Settlement" for col in settlement_pivot.columns]

        # Pivot Spot prices
        spot_pivot = df.pivot_table(
            index="Date",
            columns="ProductID",
            values="Spot",
            aggfunc="first"
        )
        spot_pivot.columns = [f"{col}_Spot" for col in spot_pivot.columns]

        # Combine both price types
        price_matrix = pd.concat([settlement_pivot, spot_pivot], axis=1)

        # Handle missing data:
        # 1. Replace 0 values with NaN (0 is likely missing data, not actual zero price)
        price_matrix = price_matrix.replace(0, np.nan)

        # 2. åˆ é™¤å…¨æ˜¯ NaN çš„åˆ—ï¼ˆæ–°æ•°æ®ç»“æ„ä¸‹ï¼ŒæœŸè´§IDæ²¡æœ‰Spotï¼Œç°è´§IDæ²¡æœ‰Settlementï¼‰
        price_matrix = price_matrix.dropna(axis=1, how='all')

        # 3. Forward fill (ffill) to handle non-trading days
        price_matrix = price_matrix.ffill()

        # 4. Backward fill for any remaining NaN at the start
        price_matrix = price_matrix.bfill()

        # Sort columns for consistent ordering
        price_matrix = price_matrix.reindex(sorted(price_matrix.columns), axis=1)

        self._price_matrix = price_matrix

        # Return latest N days
        return price_matrix.tail(lookback_days)

    def get_returns(self, lookback_days: int = 250) -> pd.DataFrame:
        """
        Calculate log returns from the price matrix.

        IMPORTANT: To preserve correlation structure, we calculate returns
        BEFORE forward-filling. Days with missing data (zeros) result in
        NaN returns which are excluded from covariance calculation.

        This prevents artificial zero returns from destroying correlations
        between related assets (e.g., Settlement vs Spot for same product).

        æ–°é€»è¾‘ï¼ˆæ–¹æ¡ˆ2ï¼‰ï¼š
        - åˆ é™¤å…¨æ˜¯ NaN çš„åˆ—ï¼ˆæœŸè´§IDæ²¡æœ‰Spotï¼Œç°è´§IDæ²¡æœ‰Settlementï¼‰

        Args:
            lookback_days: Number of trading days for the return calculation window.

        Returns:
            DataFrame of log returns with NaN for missing data days.
        """
        df = self.load_data()

        # Pivot Settlement prices (keep 0 as NaN, do NOT ffill yet)
        settlement_pivot = df.pivot_table(
            index="Date",
            columns="ProductID",
            values="Settlement",
            aggfunc="first"
        )
        settlement_pivot.columns = [f"{col}_Settlement" for col in settlement_pivot.columns]

        # Pivot Spot prices
        spot_pivot = df.pivot_table(
            index="Date",
            columns="ProductID",
            values="Spot",
            aggfunc="first"
        )
        spot_pivot.columns = [f"{col}_Spot" for col in spot_pivot.columns]

        # Combine both price types
        price_matrix_raw = pd.concat([settlement_pivot, spot_pivot], axis=1)

        # Replace 0 with NaN (0 means missing data, not actual zero price)
        price_matrix_raw = price_matrix_raw.replace(0, np.nan)

        # åˆ é™¤å…¨æ˜¯ NaN çš„åˆ—ï¼ˆæ–°æ•°æ®ç»“æ„ä¸‹ï¼ŒæœŸè´§IDæ²¡æœ‰Spotï¼Œç°è´§IDæ²¡æœ‰Settlementï¼‰
        price_matrix_raw = price_matrix_raw.dropna(axis=1, how='all')

        # Sort columns for consistent ordering
        price_matrix_raw = price_matrix_raw.reindex(sorted(price_matrix_raw.columns), axis=1)

        # Calculate log returns BEFORE ffill
        # This way, if either P_t or P_{t-1} is NaN, the return is NaN
        returns = np.log(price_matrix_raw / price_matrix_raw.shift(1))

        # Get the latest N days
        returns = returns.tail(lookback_days + 1)

        # Drop the first row (NaN from shift)
        returns = returns.iloc[1:]

        return returns

    def get_latest_prices(self) -> pd.Series:
        """
        Get the most recent price for each asset.

        Returns:
            Series with asset_id as index and latest price as value.
        """
        price_matrix = self.get_price_matrix()
        # Get the last row (most recent date)
        latest_prices = price_matrix.iloc[-1]
        return latest_prices

    def get_latest_price_date(self) -> pd.Timestamp:
        """
        Get the date of the most recent price data.

        Returns:
            Timestamp of the latest price date.
        """
        price_matrix = self.get_price_matrix()
        return price_matrix.index[-1]


# =============================================================================
# Risk Engine Class
# =============================================================================

class RiskEngine:
    """
    Risk calculation engine implementing Parametric VaR with EWMA volatility.

    Key features:
    - EWMA covariance matrix with configurable decay factor
    - Multi-asset portfolio VaR calculation
    - Support for multiple confidence levels
    - Square-root-of-time scaling for multi-day VaR
    """

    # Z-scores for standard confidence levels
    Z_SCORES = {
        0.95: 1.6449,   # 95% confidence (one-tailed)
        0.99: 2.3263    # 99% confidence (one-tailed)
    }

    def __init__(self, returns: pd.DataFrame, decay_factor: float = 0.94):
        """
        Initialize the RiskEngine.

        Args:
            returns: DataFrame of asset returns (dates as index, assets as columns).
            decay_factor: Lambda for EWMA calculation (default 0.94, industry standard).
        """
        if not 0 < decay_factor < 1:
            raise ValueError("Decay factor must be between 0 and 1")

        self.returns = returns
        self.decay_factor = decay_factor
        self._ewma_cov: Optional[np.ndarray] = None
        self.asset_names = list(returns.columns)

    def calculate_ewma_covariance(self) -> np.ndarray:
        """
        Calculate the EWMA covariance matrix with proper handling of missing data.

        Uses PAIRWISE DELETION: For each pair of assets (i, j), only uses days
        where BOTH assets have valid (non-NaN) returns. This preserves the
        correlation structure even when some assets have missing data.

        The EWMA covariance gives more weight to recent observations:
        Ïƒ_ij(t) = Î» * Ïƒ_ij(t-1) + (1-Î») * r_i(t) * r_j(t)

        Returns:
            Covariance matrix as numpy array.
        """
        if self._ewma_cov is not None:
            return self._ewma_cov

        returns_df = self.returns
        T, n_assets = returns_df.shape

        if T < 2:
            raise ValueError("Need at least 2 observations for covariance calculation")

        lambda_ = self.decay_factor

        # Generate exponential weights (most recent = highest weight)
        base_weights = np.array([(1 - lambda_) * (lambda_ ** i) for i in range(T - 1, -1, -1)])

        # Initialize covariance matrix
        cov_matrix = np.zeros((n_assets, n_assets))

        # Calculate EWMA covariance for each pair using pairwise deletion
        for i in range(n_assets):
            for j in range(i, n_assets):  # Only upper triangle (symmetric)
                # Get returns for assets i and j
                r_i = returns_df.iloc[:, i].values
                r_j = returns_df.iloc[:, j].values

                # Find days where BOTH have valid returns
                valid_mask = ~(np.isnan(r_i) | np.isnan(r_j))
                valid_indices = np.where(valid_mask)[0]

                if len(valid_indices) < 10:
                    # Not enough data - use a high variance as fallback
                    cov_matrix[i, j] = 0.001 if i == j else 0
                    cov_matrix[j, i] = cov_matrix[i, j]
                    continue

                # Extract valid returns
                r_i_valid = r_i[valid_mask]
                r_j_valid = r_j[valid_mask]

                # Get weights for valid days and renormalize
                weights_valid = base_weights[valid_mask]
                weights_valid = weights_valid / weights_valid.sum()

                # Demean returns (using weighted mean)
                mean_i = np.sum(weights_valid * r_i_valid)
                mean_j = np.sum(weights_valid * r_j_valid)
                r_i_centered = r_i_valid - mean_i
                r_j_centered = r_j_valid - mean_j

                # Calculate weighted covariance
                cov_ij = np.sum(weights_valid * r_i_centered * r_j_centered)

                cov_matrix[i, j] = cov_ij
                cov_matrix[j, i] = cov_ij  # Symmetric

        self._ewma_cov = cov_matrix
        return cov_matrix

    def calculate_portfolio_var(
        self,
        positions: np.ndarray,
        confidence: float = 0.95
    ) -> float:
        """
        Calculate portfolio VaR for a given position vector.

        VaR = sqrt(V^T Â· Î£ Â· V) Â· Z_Î±

        Args:
            positions: Position vector (signed notional amounts, positive=long, negative=short).
            confidence: Confidence level (0.95 or 0.99).

        Returns:
            VaR value in the same currency as positions.
        """
        if len(positions) != len(self.asset_names):
            raise ValueError(
                f"Position vector length ({len(positions)}) must match "
                f"number of assets ({len(self.asset_names)})"
            )

        cov_matrix = self.calculate_ewma_covariance()

        # Portfolio variance: V^T Â· Î£ Â· V
        positions = np.array(positions).flatten()  # Ensure 1D array
        portfolio_variance = positions @ cov_matrix @ positions  # Result is scalar

        # Portfolio standard deviation
        portfolio_std = np.sqrt(portfolio_variance)

        # Get Z-score for confidence level
        z_score = self.Z_SCORES.get(confidence)
        if z_score is None:
            z_score = norm.ppf(confidence)

        # VaR = Ïƒ_portfolio * Z_Î±
        var_1day = portfolio_std * z_score

        return var_1day

    def get_var_results(
        self,
        positions: np.ndarray
    ) -> Dict[str, Dict[str, float]]:
        """
        Calculate comprehensive VaR results for multiple confidence levels and horizons.

        Args:
            positions: Position vector (signed notional amounts).

        Returns:
            Dictionary with VaR values:
            {
                "1-Day": {"95%": value, "99%": value},
                "10-Day": {"95%": value, "99%": value}
            }
        """
        results = {}

        # Calculate 1-Day VaR
        var_1d_95 = self.calculate_portfolio_var(positions, 0.95)
        var_1d_99 = self.calculate_portfolio_var(positions, 0.99)

        results["1-Day"] = {
            "95%": var_1d_95,
            "99%": var_1d_99
        }

        # Calculate 10-Day VaR using square root of time rule
        sqrt_10 = np.sqrt(10)
        results["10-Day"] = {
            "95%": var_1d_95 * sqrt_10,
            "99%": var_1d_99 * sqrt_10
        }

        return results

    def get_correlation_matrix(self) -> pd.DataFrame:
        """
        Get the correlation matrix derived from EWMA covariance.

        Returns:
            DataFrame with asset correlations.
        """
        cov_matrix = self.calculate_ewma_covariance()

        # Convert covariance to correlation
        std_devs = np.sqrt(np.diag(cov_matrix))
        corr_matrix = cov_matrix / np.outer(std_devs, std_devs)

        return pd.DataFrame(
            corr_matrix,
            index=self.asset_names,
            columns=self.asset_names
        )

    def get_individual_volatilities(self) -> pd.Series:
        """
        Get annualized volatilities for each asset.

        Returns:
            Series of annualized volatilities.
        """
        cov_matrix = self.calculate_ewma_covariance()
        daily_vol = np.sqrt(np.diag(cov_matrix))
        annual_vol = daily_vol * np.sqrt(252)  # Annualize

        return pd.Series(annual_vol, index=self.asset_names)


# =============================================================================
# Streamlit UI
# =============================================================================

def format_currency(value: float, currency: str = "CNY") -> str:
    """Format a number as currency string."""
    if abs(value) >= 1_000_000:
        return f"{value:,.0f} {currency}"
    elif abs(value) >= 1_000:
        return f"{value:,.2f} {currency}"
    else:
        return f"{value:.4f} {currency}"


def create_position_input(
    asset: AssetMetadata,
    key_prefix: str
) -> Tuple[float, str]:
    """
    Create position input widgets for a single asset.

    Returns:
        Tuple of (position_size, direction)
    """
    price_type_label = "æœŸè´§å¤´å¯¸" if asset.price_type == "Settlement" else "ç°è´§å¤´å¯¸"
    currency_flag = "ğŸ‡ºğŸ‡¸" if asset.currency == "USD" else "ğŸ‡¨ğŸ‡³"

    col1, col2 = st.columns([3, 1])

    with col1:
        position = st.number_input(
            f"{price_type_label} (å•ä½: {asset.unit}) {currency_flag}",
            min_value=0.0,
            value=0.0,
            step=1.0,
            format="%.2f",
            key=f"{key_prefix}_{asset.asset_id}_pos",
            help=f"è¾“å…¥å¤´å¯¸æ•°é‡ï¼Œå•ä½: {asset.unit}ï¼Œè´§å¸: {asset.currency}"
        )

    with col2:
        direction = st.selectbox(
            "æ–¹å‘",
            options=["Long", "Short"],
            format_func=lambda x: "å¤šå¤´" if x == "Long" else "ç©ºå¤´",
            key=f"{key_prefix}_{asset.asset_id}_dir",
            label_visibility="collapsed"
        )

    return position, direction


def main():
    """Main Streamlit application."""

    st.set_page_config(
        page_title="ITG-X Risk Dashboard",
        page_icon="ğŸ›¡ï¸",
        layout="wide"
    )

    # Custom CSS for better styling
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1E3A5F;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1rem;
        color: #6B7280;
        margin-bottom: 1.5rem;
    }
    .stMetric {
        background-color: #F8FAFC;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #E2E8F0;
    }
    </style>
    """, unsafe_allow_html=True)

    st.markdown('<p class="main-header">ğŸ›¡ï¸ ITG-X Risk Dashboard</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">é›†å›¢VaRè®¡ç®—å™¨ | Group Value at Risk Calculator</p>', unsafe_allow_html=True)
    st.markdown("""
    **å‚æ•°æ³•VaR** Â· EWMAåæ–¹å·®çŸ©é˜µ (Î» = 0.94) Â· æ”¯æŒæœŸè´§ä¸ç°è´§åŸºå·®é£é™©è®¡ç®—
    """)

    st.divider()

    # =========================================================================
    # Settings Sidebar
    # =========================================================================

    with st.sidebar:
        st.header("âš™ï¸ å‚æ•°è®¾ç½®")

        # FX Rate Section
        st.subheader("æ±‡ç‡ (USD â†’ CNY)")

        # Fetch live rate
        if "fx_rate" not in st.session_state:
            rate, is_live = FXService.get_usdcny_rate()
            st.session_state.fx_rate = rate
            st.session_state.fx_is_live = is_live

        fx_status = "ğŸŸ¢ å®æ—¶" if st.session_state.fx_is_live else "ğŸŸ¡ é»˜è®¤"
        st.caption(f"çŠ¶æ€: {fx_status}")

        fx_rate = st.number_input(
            "USD/CNY æ±‡ç‡",
            min_value=1.0,
            max_value=20.0,
            value=st.session_state.fx_rate,
            step=0.01,
            format="%.4f",
            help="å®æ—¶æ±‡ç‡æ¥è‡ªYahoo Financeï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹"
        )

        if st.button("ğŸ”„ åˆ·æ–°æ±‡ç‡"):
            rate, is_live = FXService.get_usdcny_rate()
            st.session_state.fx_rate = rate
            st.session_state.fx_is_live = is_live
            st.rerun()

        st.divider()

        # Model Parameters
        st.subheader("æ¨¡å‹å‚æ•°")

        lookback = st.slider(
            "å›çœ‹å‘¨æœŸ (äº¤æ˜“æ—¥)",
            min_value=60,
            max_value=500,
            value=250,
            step=10,
            help="ç”¨äºVaRè®¡ç®—çš„å†å²äº¤æ˜“æ—¥å¤©æ•°"
        )

        decay_factor = st.slider(
            "EWMAè¡°å‡å› å­ (Î»)",
            min_value=0.90,
            max_value=0.99,
            value=0.94,
            step=0.01,
            help="Î»è¶Šå¤§ï¼Œå†å²æ•°æ®æƒé‡è¶Šé«˜ã€‚è¡Œä¸šæ ‡å‡†: 0.94"
        )

        st.divider()

        st.subheader("ğŸ“ æ•°æ®æ–‡ä»¶")
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ ä»·æ ¼æ•°æ® (å¯é€‰)",
            type=["xlsx", "xls", "csv"],
            help="ç•™ç©ºåˆ™ä½¿ç”¨é»˜è®¤æ–‡ä»¶: group VaR model.XLSX"
        )

    # =========================================================================
    # Load Data
    # =========================================================================

    # Determine file path - with session state caching
    import tempfile
    import os

    if uploaded_file is not None:
        # Cache uploaded file in session state to persist across interactions
        file_bytes = uploaded_file.getvalue()
        file_name = uploaded_file.name

        # Check if this is a new file or same as cached
        if ("uploaded_file_bytes" not in st.session_state or
            st.session_state.uploaded_file_bytes != file_bytes):
            st.session_state.uploaded_file_bytes = file_bytes
            st.session_state.uploaded_file_name = file_name

            # Save to temp file
            suffix = os.path.splitext(file_name)[1]
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                tmp.write(file_bytes)
                st.session_state.uploaded_file_path = tmp.name

        file_path = st.session_state.uploaded_file_path
        st.sidebar.success(f"âœ… å·²åŠ è½½: {st.session_state.uploaded_file_name}")

    elif "uploaded_file_path" in st.session_state:
        # Use previously uploaded file from session state
        file_path = st.session_state.uploaded_file_path
        st.sidebar.success(f"âœ… å·²åŠ è½½: {st.session_state.uploaded_file_name}")

    else:
        # Use default file
        file_path = os.path.join(os.path.dirname(__file__), "group VaR model.XLSX")

    # Initialize data ingestion
    try:
        data_ingestion = DataIngestion(file_path)
        asset_metadata = data_ingestion.get_asset_metadata()
        returns = data_ingestion.get_returns(lookback)
        latest_prices = data_ingestion.get_latest_prices()
        latest_price_date = data_ingestion.get_latest_price_date()
    except Exception as e:
        st.error(f"âŒ æ•°æ®åŠ è½½é”™è¯¯: {str(e)}")
        st.stop()

    st.info(f"ğŸ“… æœ€æ–°ä»·æ ¼æ—¥æœŸ: **{latest_price_date.strftime('%Y-%m-%d')}**")

    # Get unique products for grouping
    products = {}
    for asset in asset_metadata:
        if asset.product_id not in products:
            products[asset.product_id] = {
                "name": asset.product_name,
                "unit": asset.unit,
                "currency": asset.currency,
                "assets": []
            }
        products[asset.product_id]["assets"].append(asset)

    # =========================================================================
    # Position Input Form
    # =========================================================================

    st.header("ğŸ“ è¾“å…¥å¤´å¯¸")

    # Create tabs for CNY and USD products
    cny_products = {k: v for k, v in products.items() if v["currency"] == "CNY"}
    usd_products = {k: v for k, v in products.items() if v["currency"] == "USD"}

    tab_cny, tab_usd = st.tabs([
        f"ğŸ‡¨ğŸ‡³ äººæ°‘å¸äº§å“ ({len(cny_products)})",
        f"ğŸ‡ºğŸ‡¸ ç¾å…ƒäº§å“ ({len(usd_products)})"
    ])

    positions_input = {}

    with tab_cny:
        st.info("ğŸ’¡ è¯·è¾“å…¥å¤´å¯¸æ•°é‡ï¼Œå•ä½å¦‚æ‹¬å·æ‰€ç¤ºã€‚å¤šå¤´(Long) = åšå¤šæ•å£ï¼Œç©ºå¤´(Short) = åšç©ºæ•å£")

        # Create columns for better layout
        col1, col2 = st.columns(2)

        product_list = list(cny_products.items())
        mid = len(product_list) // 2

        for idx, (product_id, product_info) in enumerate(product_list):
            target_col = col1 if idx < mid else col2

            with target_col:
                with st.expander(f"**{product_id}** - {product_info['name']} [{product_info['unit']}]"):
                    for asset in product_info["assets"]:
                        pos, direction = create_position_input(asset, "cny")
                        positions_input[asset.asset_id] = {
                            "position": pos,
                            "direction": direction,
                            "asset": asset
                        }

    with tab_usd:
        st.warning(f"âš ï¸ ç¾å…ƒå¤´å¯¸å°†æŒ‰æ±‡ç‡ **{fx_rate:.4f}** è½¬æ¢ä¸ºäººæ°‘å¸")

        for product_id, product_info in usd_products.items():
            with st.expander(f"**{product_id}** - {product_info['name']} [{product_info['unit']}]"):
                for asset in product_info["assets"]:
                    pos, direction = create_position_input(asset, "usd")
                    positions_input[asset.asset_id] = {
                        "position": pos,
                        "direction": direction,
                        "asset": asset
                    }

    st.divider()

    # =========================================================================
    # Calculate VaR
    # =========================================================================

    col_calc, col_clear = st.columns([1, 5])

    with col_calc:
        calculate_button = st.button("ğŸ§® è®¡ç®—VaR", type="primary", width="stretch")

    with col_clear:
        if st.button("ğŸ—‘ï¸ æ¸…ç©º"):
            st.rerun()

    if calculate_button:
        # Build position vector
        position_vector = []
        active_positions = []

        # Get the asset order from returns columns
        for asset_id in returns.columns:
            if asset_id in positions_input:
                info = positions_input[asset_id]
                quantity = info["position"]  # User input is QUANTITY (e.g., tons)
                direction = info["direction"]
                asset = info["asset"]

                # Get current price for this asset
                current_price = latest_prices.get(asset_id, 0)

                # Calculate NOTIONAL VALUE = Quantity Ã— Price
                notional = quantity * current_price

                # Apply direction (Long = positive, Short = negative)
                signed_notional = notional if direction == "Long" else -notional

                # Convert USD to CNY for USD-denominated assets
                if asset.currency == "USD":
                    signed_notional *= fx_rate

                position_vector.append(signed_notional)

                if quantity != 0:
                    active_positions.append({
                        "Asset": asset.display_name,
                        "ID": asset.asset_id,
                        "Quantity": quantity,
                        "Unit": asset.unit,
                        "Price": current_price,
                        "Direction": direction,
                        "Currency": asset.currency,
                        "Notional (CNY)": abs(signed_notional)
                    })
            else:
                position_vector.append(0.0)

        position_vector = np.array(position_vector)

        # Check if any positions were entered
        if np.allclose(position_vector, 0):
            st.warning("âš ï¸ è¯·è‡³å°‘è¾“å…¥ä¸€ä¸ªéé›¶å¤´å¯¸")
        else:
            # Initialize Risk Engine
            try:
                engine = RiskEngine(returns, decay_factor=decay_factor)
                results = engine.get_var_results(position_vector)
            except Exception as e:
                st.error(f"âŒ VaRè®¡ç®—é”™è¯¯: {str(e)}")
                st.stop()

            # =========================================================================
            # Display Results
            # =========================================================================

            st.header("ğŸ“Š VaRè®¡ç®—ç»“æœ")

            # Results table
            results_df = pd.DataFrame({
                "ç½®ä¿¡æ°´å¹³": ["95%", "99%"],
                "1æ—¥VaR (CNY)": [
                    format_currency(results["1-Day"]["95%"]),
                    format_currency(results["1-Day"]["99%"])
                ],
                "10æ—¥VaR (CNY)": [
                    format_currency(results["10-Day"]["95%"]),
                    format_currency(results["10-Day"]["99%"])
                ]
            })

            # Display as metrics
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric(
                    "1æ—¥VaR (95%)",
                    format_currency(results["1-Day"]["95%"]),
                    help="95%ç½®ä¿¡åº¦ä¸‹1æ—¥æœ€å¤§é¢„æœŸæŸå¤±"
                )

            with col2:
                st.metric(
                    "1æ—¥VaR (99%)",
                    format_currency(results["1-Day"]["99%"]),
                    help="99%ç½®ä¿¡åº¦ä¸‹1æ—¥æœ€å¤§é¢„æœŸæŸå¤±"
                )

            with col3:
                st.metric(
                    "10æ—¥VaR (95%)",
                    format_currency(results["10-Day"]["95%"]),
                    help="95%ç½®ä¿¡åº¦ä¸‹10æ—¥æœ€å¤§é¢„æœŸæŸå¤± (âˆš10ç¼©æ”¾)"
                )

            with col4:
                st.metric(
                    "10æ—¥VaR (99%)",
                    format_currency(results["10-Day"]["99%"]),
                    help="99%ç½®ä¿¡åº¦ä¸‹10æ—¥æœ€å¤§é¢„æœŸæŸå¤± (âˆš10ç¼©æ”¾)"
                )

            st.divider()

            # Active Positions Summary
            st.subheader("ğŸ“‹ æŒä»“æ±‡æ€»")

            if active_positions:
                positions_df = pd.DataFrame(active_positions)

                # Rename columns to Chinese
                column_rename = {
                    "Asset": "èµ„äº§",
                    "ID": "ä»£ç ",
                    "Quantity": "æ•°é‡",
                    "Unit": "å•ä½",
                    "Price": "ä»·æ ¼",
                    "Direction": "æ–¹å‘",
                    "Currency": "è´§å¸",
                    "Notional (CNY)": "åä¹‰é‡‘é¢(CNY)"
                }

                # Format the dataframe for display
                display_df = positions_df.copy()
                display_df["Price"] = display_df["Price"].apply(lambda x: f"{x:,.2f}")
                display_df["Notional (CNY)"] = display_df["Notional (CNY)"].apply(lambda x: f"{x:,.0f}")
                display_df["Direction"] = display_df["Direction"].apply(lambda x: "å¤šå¤´" if x == "Long" else "ç©ºå¤´")
                display_df = display_df.rename(columns=column_rename)

                st.dataframe(
                    display_df,
                    width="stretch",
                    hide_index=True
                )

                # Summary stats
                total_long = sum(p["Notional (CNY)"] for p in active_positions if p["Direction"] == "Long")
                total_short = sum(p["Notional (CNY)"] for p in active_positions if p["Direction"] == "Short")

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("å¤šå¤´æ•å£", format_currency(total_long))
                with col2:
                    st.metric("ç©ºå¤´æ•å£", format_currency(total_short))
                with col3:
                    st.metric("å‡€æ•å£", format_currency(total_long - total_short))

            st.divider()

            # Volatility Analysis (Expandable)
            with st.expander("ğŸ“ˆ æ³¢åŠ¨ç‡ä¸ç›¸å…³æ€§åˆ†æ"):
                st.subheader("å¹´åŒ–æ³¢åŠ¨ç‡ (æ´»è·ƒèµ„äº§)")

                vol_series = engine.get_individual_volatilities()

                # Filter to show only active assets
                active_asset_ids = [p["ID"] for p in active_positions]
                active_vols = vol_series[vol_series.index.isin(active_asset_ids)]

                if not active_vols.empty:
                    vol_df = pd.DataFrame({
                        "èµ„äº§": active_vols.index,
                        "å¹´åŒ–æ³¢åŠ¨ç‡": [f"{v*100:.2f}%" for v in active_vols.values]
                    })
                    st.dataframe(vol_df, width="stretch", hide_index=True)

                st.subheader("ç›¸å…³ç³»æ•°çŸ©é˜µ (æ´»è·ƒèµ„äº§)")

                corr_matrix = engine.get_correlation_matrix()

                if len(active_asset_ids) > 1:
                    # Filter correlation matrix to active assets
                    active_corr = corr_matrix.loc[
                        corr_matrix.index.isin(active_asset_ids),
                        corr_matrix.columns.isin(active_asset_ids)
                    ]

                    # Format as percentage
                    st.dataframe(
                        active_corr.style.format("{:.2%}").background_gradient(cmap="RdYlGn", vmin=-1, vmax=1),
                        width="stretch"
                    )
                else:
                    st.info("è¾“å…¥2ä¸ªä»¥ä¸Šèµ„äº§å¤´å¯¸å¯æŸ¥çœ‹ç›¸å…³ç³»æ•°çŸ©é˜µ")

    # =========================================================================
    # Footer
    # =========================================================================

    st.divider()
    st.caption(f"""
    **æ¨¡å‹è¯´æ˜:**
    - æ–¹æ³•: å‚æ•°æ³•VaR (æ–¹å·®-åæ–¹å·®æ³•)
    - æ³¢åŠ¨ç‡: EWMAè¡°å‡å› å­ Î» = {decay_factor}
    - å›çœ‹å‘¨æœŸ: {lookback} äº¤æ˜“æ—¥
    - 10æ—¥VaR: æ—¶é—´å¹³æ–¹æ ¹ç¼©æ”¾ (âˆš10)
    - æ•°æ®: {len(products)} ä¸ªäº§å“ Ã— 2 ç§ä»·æ ¼ç±»å‹ = {len(asset_metadata)} ä¸ªèµ„äº§
    """)
    st.caption("Â© 2026 ITG-Xç³»ç»Ÿ | Powered by EWMA Risk Engine")


if __name__ == "__main__":
    main()
